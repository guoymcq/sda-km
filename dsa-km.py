import timeitimport scipyimport numpy as npimport pickleimport gzipimport tensorflow as tffrom cluster_acc import accfrom sklearn import metricsfrom sklearn.cluster import KMeansclass DA(object):    """A denoising autoencoder class (using tied weight)"""    def __init__(self, inpt, n_visiable=784, n_hidden=500, W=None, bhid=None,                 bvis=None):        """        inpt: tf.Tensor, the input        :param n_visiable: int, number of hidden units        :param n_hidden: int, number of visable units        :param W, bhid, bvis: tf.Tensor, the weight, bias tensor        """        self.n_visiable = n_visiable        self.n_hidden = n_hidden        # initialize the weight and bias if not given        if W is None:            bound = 1/np.sqrt(self.n_visiable)            W = tf.Variable(bound*tf.random_normal([self.n_visiable, self.n_hidden], mean=0.0, stddev=1.0),                            dtype=tf.float32)        if bhid is None:            bhid = tf.Variable(tf.zeros([n_hidden, ]), dtype=tf.float32)        if bvis is None:            bvis = tf.Variable(tf.zeros([n_visiable, ]), dtype=tf.float32)        self.W = W        self.b = bhid        # reconstruct params        self.b_prime = bvis        self.W_prime = tf.transpose(self.W)        # keep track of input and params        self.input = inpt        self.params = [self.W, self.b, self.b_prime]        # output        self.output = self.get_encode_values(inpt)    def get_encode_values(self, inpt):        """Compute the encode values"""        # the output        sum_W = tf.matmul(inpt, self.W) + self.b        output = tf.nn.relu(sum_W)        return output    def get_decode_values(self, encode_input):        """Get the reconstructed values"""        sum_W = tf.matmul(encode_input, self.W_prime) + self.b_prime        output = tf.nn.relu(sum_W)        return output    def get_corrupted_input(self, inpt, corruption_level):        """        Randomly zero the element of input        corruption_level: float, (0,1]        """        # the shape of input        input_shape = tf.shape(inpt)        # the probablity for corruption        probs = tf.tile(tf.log([[corruption_level, 1 - corruption_level]]),                        multiples=[input_shape[0], 1])        return tf.multiply(tf.cast(tf.multinomial(probs, num_samples=input_shape[1]),                                   dtype=tf.float32), inpt)    def get_cost(self, corruption_level=0.0):        """Get the cost for training"""        corrupted_input = self.get_corrupted_input(self.input, corruption_level)        encode_output = self.get_encode_values(corrupted_input)        decode_output = self.get_decode_values(encode_output)        # use squared distance        dist = tf.reduce_sum(tf.pow(decode_output-self.input, 2), axis=1)        cost = tf.reduce_mean(dist)        # cost = 0.5*dist*1/self.input.shape[0]        return costclass DA_linear_hidden(DA):    def get_encode_values(self, inpt):        """Compute the encode values"""        # the output        output = tf.matmul(inpt, self.W) + self.b        return outputclass DA_linear_out(DA):    def get_decode_values(self, encode_input):        """Compute the encode values"""        # the output        output = tf.matmul(encode_input, self.W_prime) + self.b_prime        return outputclass SdA(object):    def __init__(self, n_in=784, n_out=10, hidden_layers_sizes=(500, 500),                 corruption_levels=(0.0, 0.0), n_cluster=10):        assert len(hidden_layers_sizes) >= 1        assert len(hidden_layers_sizes) == len(corruption_levels)        self.corruption_levels = corruption_levels        self.n_layers = len(hidden_layers_sizes)        # define the layers        self.dA_layers = []  # the dA layers        self.params = []  # params        # define the input and output        self.x = tf.placeholder(tf.float32, shape=[None, n_in])        self.y = tf.placeholder(tf.float32, shape=[None, n_out])        self.center = tf.placeholder(tf.float32, shape=[n_cluster, hidden_layers_sizes[-1]])        self.idx = tf.placeholder(tf.float32, shape=[None, n_cluster])        self.lbd = 1.0        self.beta = 1.0        # construct the layers        for i in range(self.n_layers):            if i == 0:  # the input layer                input_size = n_in                layer_input = self.x            else:                input_size = hidden_layers_sizes[i - 1]                layer_input = self.dA_layers[i - 1].output            # create the dA layer            if i == self.n_layers - 1:                dA_layer = DA_linear_hidden(inpt=layer_input, n_hidden=hidden_layers_sizes[i],                                            n_visiable=input_size)            elif i == 0:                dA_layer = DA_linear_out(inpt=layer_input, n_hidden=hidden_layers_sizes[i],                                         n_visiable=input_size)            else:                dA_layer = DA(inpt=layer_input, n_hidden=hidden_layers_sizes[i],                              n_visiable=input_size)            self.dA_layers.append(dA_layer)            # collect the params            self.params.extend(dA_layer.params)    def get_network_reconst(self):        reconst = self.dA_layers[-1].get_encode_values(self.dA_layers[-1].input)        for da in reversed(self.dA_layers):            reconst = da.get_decode_values(reconst)        # use squared distance        dist = tf.reduce_sum(tf.pow(reconst-self.x, 2), axis=1)        cost = tf.reduce_mean(dist)        return cost    def get_network_output(self):        output = self.dA_layers[-1].get_encode_values(self.dA_layers[-1].input)        #output = self.x        #for da in self.dA_layers:        #    output = da.get_encode_values(output)        return output    def get_network_reconst_output(self):        reconst = self.dA_layers[-1].get_encode_values(self.dA_layers[-1].input)        for da in reversed(self.dA_layers):            reconst = da.get_decode_values(reconst)        return reconst    def pretrain(self, sess, X_train, pretraining_epochs=250,                 batch_size=256, learning_rate=0.0001, momentum=0.9, display_step=1):        print("Starting pretraing...")        start_time = timeit.default_timer()        n = len(X_train[0])        batch_num = int(n / batch_size)        for i in range(self.n_layers):            # pretraining layer by layer            cost = self.dA_layers[i].get_cost(corruption_level=self.corruption_levels[i])            params = self.dA_layers[i].params            optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)            train_op = optimizer.minimize(cost, var_list=params)            init = tf.initialize_all_variables()            sess.run(init)            for epoch in range(pretraining_epochs):                avg_cost = 0.0                mini_batches = [X_train[0][k:k + batch_size]                                for k in range(batch_num)]                for mini_batch in mini_batches:                    x_batch = mini_batch                    # training                    sess.run(train_op, feed_dict={self.x: x_batch})                    # computing cost                    avg_cost += sess.run(cost, feed_dict={self.x: x_batch}) / batch_num                # print                if epoch % display_step == 0:                    print("Pretraining layer {0} Epoch {1} cost: {2}".format(i, epoch, avg_cost))        end_time = timeit.default_timer()        print("The pretraining process ran for {}m".format((end_time - start_time) / 60))        output = self.get_network_output()        h_output = sess.run(output, feed_dict={self.x: X_train[0]})        idx, center = init_cluster(h_output)        label_true = X_train[1]        ac = acc(idx, label_true)        nmi = metrics.normalized_mutual_info_score(label_true, idx)        ari = metrics.adjusted_rand_score(label_true, idx)        print("after pretraining, acc:{0} nmi: {1} ari {2}".format(ac, nmi, ari))class SdC_KM(SdA):    """    This class implements DCN with K-means clustering model    """    def finetune_cost_all(self):        """ This function computes the cost and the updates ."""        # note : we sum over the size of a datapoint; if we are using        #        minibatches, L will be a vector, withd one entry per        #        example in minibatch        network_output = self.get_network_output()        temp = tf.pow(tf.matmul(self.idx, self.center)-network_output, 2)        l = tf.reduce_sum(temp, axis=1)        # Add the network reconstruction error        z = self.get_network_reconst_output()        reconst_err = tf.reduce_sum(tf.pow(self.x-z, 2), axis=1)        s = self.beta * l + self.lbd * reconst_err        cost1 = tf.reduce_mean(s)        #cost2 = self.lbd * tf.reduce_mean(reconst_err)        #cost3 = cost1 - cost2        return cost1    def finetuning(self, sess, trainSet, center, momentum=0.9, training_epochs=50, batch_size=256,                   learning_rate=0.0001, display_step=1):        """"Finetuning the network"""        print("Start finetuning...")        start_time = timeit.default_timer()        n = len(trainSet[0])        batch_num = int(n / batch_size)        count = 100 * np.ones(10, dtype=np.int)        output = self.get_network_output()        center = center        cost_all = self.finetune_cost_all()        optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)        train_op = optimizer.minimize(cost_all, var_list=self.params)        init = tf.initialize_all_variables()        sess.run(init)                                   for epoch in range(training_epochs):            avg_cost = 0.0            mini_batches = [trainSet[0][k:k + batch_size]                            for k in range(batch_num)]            for mini_batch in mini_batches:                x_batch = mini_batch                x_data = sess.run(output, feed_dict={self.x: x_batch})                idx, center, count = batch_km(x_data, center, count)                idx = [vectorized_result(y) for y in idx]                # training                _ = sess.run(train_op, feed_dict={self.x: x_batch, self.center: center, self.idx: idx})                avg_cost = sess.run(cost_all, feed_dict={self.x: x_batch, self.center: center, self.idx: idx})                # computing cost                avg_cost += avg_cost            # print                                        avg_cost = avg_cost / batch_num            if epoch % display_step == 0:                print("Epoch {0} cost: {1}".format(epoch, avg_cost))        end_time = timeit.default_timer()        print("The finetuning process ran for {}m".format((end_time - start_time) / 60))        h_output = sess.run(output, feed_dict={self.x: trainSet[0]})        km_model = KMeans(n_clusters=10, init=center)        # check if joint training indeed improve clustering        idx_new = km_model.fit_predict(h_output)        idx = idx_new        label_true = trainSet[1]        ac = acc(idx, label_true)        nmi = metrics.normalized_mutual_info_score(label_true, idx)        ari = metrics.adjusted_rand_score(label_true, idx)        print("acc:{0} nmi: {1} ari {2}".format(ac, nmi, ari))def vectorized_result(j):    """Return a 10-dimensional unit vector with a 1.0 in the jth    position and zeroes elsewhere.  This is used to convert a digit    (0...9) into a corresponding desired output from the neural    network."""    e = np.zeros(10)    e[j] = 1.0    return edef batch_km(data, center, count):    """    Function to perform a KMeans update on a batch of data, center is the    centroid from last iteration.    """    N = data.shape[0]    K = center.shape[0]    # update assignment    idx = np.zeros(N, dtype=np.int)    for i in range(N):        dist = np.inf        ind = 0        for j in range(K):            temp_dist = np.linalg.norm(data[i] - center[j])            if temp_dist < dist:                dist = temp_dist                ind = j        idx[i] = ind    # update centriod    center_new = center    for i in range(N):        c = idx[i]        count[c] += 1        eta = 1.0 / count[c]        center_new[c] = (1 - eta) * center_new[c] + eta * data[i]    center_new.astype(np.float32)    return idx, center_new, countdef load_data(dataset):    """    Load the dataset, perform shuffling    """    with gzip.open(dataset, 'rb') as f:        train_x, train_y = pickle.load(f, encoding='bytes')    if scipy.sparse.issparse(train_x):        train_x = train_x.toarray()    if train_x.dtype != 'float32':        train_x = train_x.astype(np.float32)    if train_y.dtype != 'int32':        train_y = train_y.astype(np.int32)    if train_y.ndim > 1:        train_y = np.squeeze(train_y)    N = train_x.shape[0]    idx = np.random.permutation(N)    train_x = train_x[idx]    train_y = train_y[idx]    return train_x, train_ydef init_cluster(data):    km = KMeans(n_clusters=10, n_init=10)    km.fit(data)    idx = km.labels_    centers = km.cluster_centers_    centers = centers.astype(np.float32)    idx = idx.astype(np.int32)    return idx, centersif __name__ == "__main__":    # mnist examples    mnist = load_data("mnist_dcn.pkl.gz")    sda = SdC_KM(n_in=784, n_out=10, hidden_layers_sizes=[500, 500, 2000, 10],              corruption_levels=[0.0, 0.0, 0.0, 0.0])    sess = tf.Session()    init = tf.global_variables_initializer()    sess.run(init)    # set random_seed    tf.set_random_seed(seed=1111)    saver = tf.train.Saver()    #sda.pretrain(sess, X_train=mnist, momentum=0.9)    #saver.save(sess, "my-test-model")    saver.restore(sess, "my-test-model")    output = sda.get_network_output()    h_output = sess.run(output, feed_dict={sda.x: mnist[0]})    idx, center = init_cluster(h_output)    label_true = mnist[1]    ac = acc(idx, label_true)    nmi = metrics.normalized_mutual_info_score(label_true, idx)    ari = metrics.adjusted_rand_score(label_true, idx)    print("after pretraining, acc:{0} nmi: {1} ari {2}".format(ac, nmi, ari))    sda.finetuning(sess, trainSet=mnist, center=center, momentum=0.9)    sess.close()